{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb1968a-accd-45bf-8e58-3ef320501f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/spark-3.4.2-bin-hadoop3/python (3.4.2)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in ./lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f48b50",
   "metadata": {},
   "source": [
    "# Data preparation and processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c351cf2",
   "metadata": {},
   "source": [
    "Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e27b2c-ca35-4cfd-9bec-2356ef3f234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15442163-f88f-46dc-8d25-7c449872b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364bdf91-cc93-4974-aa4c-cb8acaa6d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Tweets\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5bbb63-1084-4055-99d3-c8cf69092f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# CVS\n",
    "path = \"file:///home/hduser/myenv/ProjectTweets.csv\"\n",
    "\n",
    "df = spark.read.csv(path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61790b6",
   "metadata": {},
   "source": [
    "Analysis of the file format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad0d575-5de1-466b-84b3-c6db225dd830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- 1467810369: long (nullable = true)\n",
      " |-- Mon Apr 06 22:19:45 PDT 2009: string (nullable = true)\n",
      " |-- NO_QUERY: string (nullable = true)\n",
      " |-- _TheSpecialOne_: string (nullable = true)\n",
      " |-- @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DataFrame\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf353ef8-942c-45ff-895d-00e0876170ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:45 PDT 2009|NO_QUERY|_TheSpecialOne_|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|  1|1467810672|        Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|                                                                                               is upset that he ...|\n",
      "|  2|1467810917|        Mon Apr 06 22:19:...|NO_QUERY|       mattycus|                                                                                               @Kenichan I dived...|\n",
      "|  3|1467811184|        Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|                                                                                               my whole body fee...|\n",
      "|  4|1467811193|        Mon Apr 06 22:19:...|NO_QUERY|         Karoli|                                                                                               @nationwideclass ...|\n",
      "|  5|1467811372|        Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|                                                                                               @Kwesidei not the...|\n",
      "|  6|1467811592|        Mon Apr 06 22:20:...|NO_QUERY|        mybirch|                                                                                                        Need a hug |\n",
      "|  7|1467811594|        Mon Apr 06 22:20:...|NO_QUERY|           coZZ|                                                                                               @LOLTrish hey  lo...|\n",
      "|  8|1467811795|        Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|                                                                                               @Tatiana_K nope t...|\n",
      "|  9|1467812025|        Mon Apr 06 22:20:...|NO_QUERY|        mimismo|                                                                                               @twittera que me ...|\n",
      "| 10|1467812416|        Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|                                                                                               spring break in p...|\n",
      "| 11|1467812579|        Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|                                                                                               I just re-pierced...|\n",
      "| 12|1467812723|        Mon Apr 06 22:20:...|NO_QUERY|           TLeC|                                                                                               @caregiving I cou...|\n",
      "| 13|1467812771|        Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|                                                                                               @octolinz16 It it...|\n",
      "| 14|1467812784|        Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|                                                                                               @smarrison i woul...|\n",
      "| 15|1467812799|        Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|                                                                                               @iamjazzyfizzle I...|\n",
      "| 16|1467812964|        Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|                                                                                               Hollis' death sce...|\n",
      "| 17|1467813137|        Mon Apr 06 22:20:...|NO_QUERY|       armotley|                                                                                               about to file taxes |\n",
      "| 18|1467813579|        Mon Apr 06 22:20:...|NO_QUERY|     starkissed|                                                                                               @LettyA ahh ive a...|\n",
      "| 19|1467813782|        Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|                                                                                               @FakerPattyPattz ...|\n",
      "| 20|1467813985|        Mon Apr 06 22:20:...|NO_QUERY|         quanvu|                                                                                               @alydesigns i was...|\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d367ef8b-6a98-4916-b588-dfd2b14f7bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1599999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca88cf5",
   "metadata": {},
   "source": [
    "#Create a new Dataframe from the original file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f37e332-d747-4944-a961-f3a016843246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (IntegerType, StringType, \n",
    "                               TimestampType, StructType,\n",
    "                               StructField, ArrayType,\n",
    "                               TimestampType)\n",
    "\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "198c945b-91ed-48c2-900b-195bc84763d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_schema = StructType([\n",
    "    StructField(\"new_number\", StringType(), True),\n",
    "    StructField(\"new__id\", StringType(), True),\n",
    "    StructField(\"new_date\", StringType(), True),\n",
    "    StructField(\"new_flag\", StringType(), True),\n",
    "    StructField(\"new_user\", StringType(), True),\n",
    "    StructField(\"new_tweet\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87d10005-83cb-4c45-a0de-8fd44368efd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- new_number: string (nullable = true)\n",
      " |-- new__id: string (nullable = true)\n",
      " |-- new_date: string (nullable = true)\n",
      " |-- new_flag: string (nullable = true)\n",
      " |-- new_user: string (nullable = true)\n",
      " |-- new_tweet: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(df.rdd, schema=new_schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7193d0-738c-4b0b-b38d-a53107b5bc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- number: string (nullable = true)\n",
      " |-- _id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_names = df.columns\n",
    "\n",
    "# Rename columns\n",
    "for old_name in column_names:\n",
    "    new_name = old_name.replace(\"new_\", \"\")\n",
    "    df = df.withColumnRenamed(old_name, new_name)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3705dfd",
   "metadata": {},
   "source": [
    "New data frame structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc824904-cfa3-4940-83f3-9f8978ed13f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|number|       _id|                date|    flag|           user|               tweet|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|     1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|     2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|     3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|     4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|     5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|     6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|     7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|     8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|     9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "|    10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "|    11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "|    12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "|    13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "|    14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "|    15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "|    16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "|    17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "|    18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "|    19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "|    20|1467813985|Mon Apr 06 22:20:...|NO_QUERY|         quanvu|@alydesigns i was...|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed61602",
   "metadata": {},
   "source": [
    "A future projection will be made so the time column is important, the format of that column is displayed to be able to separate it into different columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eda08462-01e5-415c-a14b-587fccdfde6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(date='Mon Apr 06 22:19:49 PDT 2009'),\n",
       " Row(date='Mon Apr 06 22:19:53 PDT 2009')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"date\").take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6381f3b-ebbc-44e2-8602-0830b10f3ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries \n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45837a20",
   "metadata": {},
   "source": [
    "Day of the week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6df31d77-aea8-4257-8c3d-19953df27684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DayWeek(s : str) -> str:\n",
    "    \"\"\"\n",
    "    Converts the string from the tweets to day of week by \n",
    "    extracting the first three characters from the string\n",
    "    \n",
    "    \"\"\"\n",
    "    day      =  s[:3]\n",
    "    newday  = \"\"\n",
    "    \n",
    "    if day   == \"Sun\":\n",
    "        newday = \"Sunday\"\n",
    "    elif day == \"Mon\":\n",
    "        newday = \"Monday\"\n",
    "    elif day == \"Tue\":\n",
    "        newday = \"Tuesday\"\n",
    "    elif day == \"Wed\":\n",
    "        newday = \"Wednesday\"\n",
    "    elif day == \"Thu\":\n",
    "        newday = \"Thursday\"\n",
    "    elif day == \"Fri\":\n",
    "        newday = \"Friday\"\n",
    "    else:\n",
    "        newday = \"Saturday\"\n",
    "    \n",
    "    return newday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a27e2c3b-7008-4131-9886-b25fb4d4d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a User Defined Function (UDF) in Spark to apply the DayWeek function to the data in a DataFrame\n",
    "DayDF = F.udf(DayWeek, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98e4d765-3d82-4b1f-b281-a73a99113aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"DayWeek\", DayDF(df[\"date\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee5d023e-dfa3-4663-bec3-f660cda721ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+--------+---------------+--------------------+-------+\n",
      "|number|       _id|                date|    flag|           user|               tweet|DayWeek|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+-------+\n",
      "|     1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...| Monday|\n",
      "|     2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...| Monday|\n",
      "|     3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...| Monday|\n",
      "|     4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...| Monday|\n",
      "|     5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...| Monday|\n",
      "|     6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug | Monday|\n",
      "|     7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...| Monday|\n",
      "|     8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...| Monday|\n",
      "|     9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...| Monday|\n",
      "|    10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...| Monday|\n",
      "|    11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...| Monday|\n",
      "|    12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...| Monday|\n",
      "|    13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...| Monday|\n",
      "|    14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...| Monday|\n",
      "|    15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...| Monday|\n",
      "|    16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...| Monday|\n",
      "|    17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes | Monday|\n",
      "|    18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...| Monday|\n",
      "|    19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...| Monday|\n",
      "|    20|1467813985|Mon Apr 06 22:20:...|NO_QUERY|         quanvu|@alydesigns i was...| Monday|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cfbd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract remaining date information in different columns from the original column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f20f2e05-25e0-452a-a99d-b3b081a04662",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Split Date Column\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6f2ad60-c2e4-444f-8638-051221dfe6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+--------+---------------+--------------------+-------+----+\n",
      "|number|       _id|                date|    flag|           user|               tweet|DayWeek|year|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+-------+----+\n",
      "|     1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...| Monday|2009|\n",
      "|     2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...| Monday|2009|\n",
      "|     3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...| Monday|2009|\n",
      "|     4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...| Monday|2009|\n",
      "|     5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...| Monday|2009|\n",
      "|     6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug | Monday|2009|\n",
      "|     7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...| Monday|2009|\n",
      "|     8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...| Monday|2009|\n",
      "|     9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...| Monday|2009|\n",
      "|    10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...| Monday|2009|\n",
      "|    11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...| Monday|2009|\n",
      "|    12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...| Monday|2009|\n",
      "|    13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...| Monday|2009|\n",
      "|    14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...| Monday|2009|\n",
      "|    15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...| Monday|2009|\n",
      "|    16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...| Monday|2009|\n",
      "|    17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes | Monday|2009|\n",
      "|    18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...| Monday|2009|\n",
      "|    19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...| Monday|2009|\n",
      "|    20|1467813985|Mon Apr 06 22:20:...|NO_QUERY|         quanvu|@alydesigns i was...| Monday|2009|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp\n",
    "\n",
    "# Timestamp format\n",
    "df2 = df.withColumn(\"date\", to_timestamp(\"date\", \"EEE MMM dd HH:mm:ss zzz yyyy\"))\n",
    "\n",
    "# Year\n",
    "df2 = df.withColumn(\"year\", df.date.substr(-4, 4))        \n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c597f57-45b0-480a-b759-21e2790e740d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+--------+---------------+--------------------+-------+----+---+--------+-----+\n",
      "|number|       _id|                date|    flag|           user|               tweet|DayWeek|year|day|    hour|month|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+-------+----+---+--------+-----+\n",
      "|     1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...| Monday|2009| 06|22:19:49|   pr|\n",
      "|     2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...| Monday|2009| 06|22:19:53|   pr|\n",
      "|     3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...| Monday|2009| 06|22:19:57|   pr|\n",
      "|     4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...| Monday|2009| 06|22:19:57|   pr|\n",
      "|     5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...| Monday|2009| 06|22:20:00|   pr|\n",
      "|     6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug | Monday|2009| 06|22:20:03|   pr|\n",
      "|     7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...| Monday|2009| 06|22:20:03|   pr|\n",
      "|     8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...| Monday|2009| 06|22:20:05|   pr|\n",
      "|     9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...| Monday|2009| 06|22:20:09|   pr|\n",
      "|    10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...| Monday|2009| 06|22:20:16|   pr|\n",
      "|    11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...| Monday|2009| 06|22:20:17|   pr|\n",
      "|    12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...| Monday|2009| 06|22:20:19|   pr|\n",
      "|    13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...| Monday|2009| 06|22:20:19|   pr|\n",
      "|    14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...| Monday|2009| 06|22:20:20|   pr|\n",
      "|    15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...| Monday|2009| 06|22:20:20|   pr|\n",
      "|    16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...| Monday|2009| 06|22:20:22|   pr|\n",
      "|    17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes | Monday|2009| 06|22:20:25|   pr|\n",
      "|    18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...| Monday|2009| 06|22:20:31|   pr|\n",
      "|    19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...| Monday|2009| 06|22:20:34|   pr|\n",
      "|    20|1467813985|Mon Apr 06 22:20:...|NO_QUERY|         quanvu|@alydesigns i was...| Monday|2009| 06|22:20:37|   pr|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+-------+----+---+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Day, Hour and Month\n",
    "df2 = df2.withColumn(\"day\", df2.date.substr(9, 2))          \n",
    "df2 = df2.withColumn(\"hour\", df2.date.substr(12, 8))       \n",
    "df2 = df2.withColumn(\"month\", df2.date.substr(6, 2))        \n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9da64",
   "metadata": {},
   "source": [
    "The month extraction was erroneously so the code is changed to correct it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af7703aa-664d-4ceb-8e2b-38e64e4028ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------------------+--------+---------------+--------------------+-------+----+---+--------+-----+\n",
      "|number|       _id|               date|    flag|           user|               tweet|DayWeek|year|day|    hour|month|\n",
      "+------+----------+-------------------+--------+---------------+--------------------+-------+----+---+--------+-----+\n",
      "|     1|1467810672|2009-04-07 06:19:49|NO_QUERY|  scotthamilton|is upset that he ...| Monday|2009| 06|22:19:49|    4|\n",
      "|     2|1467810917|2009-04-07 06:19:53|NO_QUERY|       mattycus|@Kenichan I dived...| Monday|2009| 06|22:19:53|    4|\n",
      "|     3|1467811184|2009-04-07 06:19:57|NO_QUERY|        ElleCTF|my whole body fee...| Monday|2009| 06|22:19:57|    4|\n",
      "|     4|1467811193|2009-04-07 06:19:57|NO_QUERY|         Karoli|@nationwideclass ...| Monday|2009| 06|22:19:57|    4|\n",
      "|     5|1467811372|2009-04-07 06:20:00|NO_QUERY|       joy_wolf|@Kwesidei not the...| Monday|2009| 06|22:20:00|    4|\n",
      "|     6|1467811592|2009-04-07 06:20:03|NO_QUERY|        mybirch|         Need a hug | Monday|2009| 06|22:20:03|    4|\n",
      "|     7|1467811594|2009-04-07 06:20:03|NO_QUERY|           coZZ|@LOLTrish hey  lo...| Monday|2009| 06|22:20:03|    4|\n",
      "|     8|1467811795|2009-04-07 06:20:05|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...| Monday|2009| 06|22:20:05|    4|\n",
      "|     9|1467812025|2009-04-07 06:20:09|NO_QUERY|        mimismo|@twittera que me ...| Monday|2009| 06|22:20:09|    4|\n",
      "|    10|1467812416|2009-04-07 06:20:16|NO_QUERY| erinx3leannexo|spring break in p...| Monday|2009| 06|22:20:16|    4|\n",
      "|    11|1467812579|2009-04-07 06:20:17|NO_QUERY|   pardonlauren|I just re-pierced...| Monday|2009| 06|22:20:17|    4|\n",
      "|    12|1467812723|2009-04-07 06:20:19|NO_QUERY|           TLeC|@caregiving I cou...| Monday|2009| 06|22:20:19|    4|\n",
      "|    13|1467812771|2009-04-07 06:20:19|NO_QUERY|robrobbierobert|@octolinz16 It it...| Monday|2009| 06|22:20:19|    4|\n",
      "|    14|1467812784|2009-04-07 06:20:20|NO_QUERY|    bayofwolves|@smarrison i woul...| Monday|2009| 06|22:20:20|    4|\n",
      "|    15|1467812799|2009-04-07 06:20:20|NO_QUERY|     HairByJess|@iamjazzyfizzle I...| Monday|2009| 06|22:20:20|    4|\n",
      "|    16|1467812964|2009-04-07 06:20:22|NO_QUERY| lovesongwriter|Hollis' death sce...| Monday|2009| 06|22:20:22|    4|\n",
      "|    17|1467813137|2009-04-07 06:20:25|NO_QUERY|       armotley|about to file taxes | Monday|2009| 06|22:20:25|    4|\n",
      "|    18|1467813579|2009-04-07 06:20:31|NO_QUERY|     starkissed|@LettyA ahh ive a...| Monday|2009| 06|22:20:31|    4|\n",
      "|    19|1467813782|2009-04-07 06:20:34|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...| Monday|2009| 06|22:20:34|    4|\n",
      "|    20|1467813985|2009-04-07 06:20:37|NO_QUERY|         quanvu|@alydesigns i was...| Monday|2009| 06|22:20:37|    4|\n",
      "+------+----------+-------------------+--------+---------------+--------------------+-------+----+---+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import month, to_timestamp\n",
    "\n",
    "df2 = df2.withColumn(\"date\", to_timestamp(\"date\", \"EEE MMM dd HH:mm:ss zzz yyyy\"))\n",
    "\n",
    "# Month\n",
    "df2 = df2.withColumn(\"month\", month(\"date\"))\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ad88d31-999c-422c-8e8b-88d51f475d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------------------+--------+---------------+--------------------+-------+----+---+--------+-----+\n",
      "|number|       _id|               date|    flag|           user|               tweet|DayWeek|year|day|    hour|month|\n",
      "+------+----------+-------------------+--------+---------------+--------------------+-------+----+---+--------+-----+\n",
      "|     1|1467810672|2009-04-07 06:19:49|NO_QUERY|  scotthamilton|is upset that he ...| Monday|2009| 06|22:19:49|    4|\n",
      "|     2|1467810917|2009-04-07 06:19:53|NO_QUERY|       mattycus|@Kenichan I dived...| Monday|2009| 06|22:19:53|    4|\n",
      "|     3|1467811184|2009-04-07 06:19:57|NO_QUERY|        ElleCTF|my whole body fee...| Monday|2009| 06|22:19:57|    4|\n",
      "|     4|1467811193|2009-04-07 06:19:57|NO_QUERY|         Karoli|@nationwideclass ...| Monday|2009| 06|22:19:57|    4|\n",
      "|     5|1467811372|2009-04-07 06:20:00|NO_QUERY|       joy_wolf|@Kwesidei not the...| Monday|2009| 06|22:20:00|    4|\n",
      "|     6|1467811592|2009-04-07 06:20:03|NO_QUERY|        mybirch|         Need a hug | Monday|2009| 06|22:20:03|    4|\n",
      "|     7|1467811594|2009-04-07 06:20:03|NO_QUERY|           coZZ|@LOLTrish hey  lo...| Monday|2009| 06|22:20:03|    4|\n",
      "|     8|1467811795|2009-04-07 06:20:05|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...| Monday|2009| 06|22:20:05|    4|\n",
      "|     9|1467812025|2009-04-07 06:20:09|NO_QUERY|        mimismo|@twittera que me ...| Monday|2009| 06|22:20:09|    4|\n",
      "|    10|1467812416|2009-04-07 06:20:16|NO_QUERY| erinx3leannexo|spring break in p...| Monday|2009| 06|22:20:16|    4|\n",
      "|    11|1467812579|2009-04-07 06:20:17|NO_QUERY|   pardonlauren|I just re-pierced...| Monday|2009| 06|22:20:17|    4|\n",
      "|    12|1467812723|2009-04-07 06:20:19|NO_QUERY|           TLeC|@caregiving I cou...| Monday|2009| 06|22:20:19|    4|\n",
      "|    13|1467812771|2009-04-07 06:20:19|NO_QUERY|robrobbierobert|@octolinz16 It it...| Monday|2009| 06|22:20:19|    4|\n",
      "|    14|1467812784|2009-04-07 06:20:20|NO_QUERY|    bayofwolves|@smarrison i woul...| Monday|2009| 06|22:20:20|    4|\n",
      "|    15|1467812799|2009-04-07 06:20:20|NO_QUERY|     HairByJess|@iamjazzyfizzle I...| Monday|2009| 06|22:20:20|    4|\n",
      "|    16|1467812964|2009-04-07 06:20:22|NO_QUERY| lovesongwriter|Hollis' death sce...| Monday|2009| 06|22:20:22|    4|\n",
      "|    17|1467813137|2009-04-07 06:20:25|NO_QUERY|       armotley|about to file taxes | Monday|2009| 06|22:20:25|    4|\n",
      "|    18|1467813579|2009-04-07 06:20:31|NO_QUERY|     starkissed|@LettyA ahh ive a...| Monday|2009| 06|22:20:31|    4|\n",
      "|    19|1467813782|2009-04-07 06:20:34|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...| Monday|2009| 06|22:20:34|    4|\n",
      "|    20|1467813985|2009-04-07 06:20:37|NO_QUERY|         quanvu|@alydesigns i was...| Monday|2009| 06|22:20:37|    4|\n",
      "+------+----------+-------------------+--------+---------------+--------------------+-------+----+---+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# String\n",
    "df2 = df2.withColumn(\"year\", col(\"year\").cast(\"string\"))\n",
    "df2 = df2.withColumn(\"day\", col(\"day\").cast(\"string\"))\n",
    "df2 = df2.withColumn(\"hour\", col(\"hour\").cast(\"string\"))\n",
    "df2 = df2.withColumn(\"month\", col(\"month\").cast(\"string\"))\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0cac95",
   "metadata": {},
   "source": [
    "Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9f6139e-0fce-488d-a84b-5f45911024bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|summary|    flag|\n",
      "+-------+--------+\n",
      "|  count| 1599999|\n",
      "|   mean|    null|\n",
      "| stddev|    null|\n",
      "|    min|NO_QUERY|\n",
      "|    max|NO_QUERY|\n",
      "+-------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Data in Column\n",
    "df2.select(\"flag\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fff93f4f-166a-40ff-8a2b-014c9d410be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are NO null values in the DataFrame.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Missing Data\n",
    "Nulls = False\n",
    "for column in df2.columns:\n",
    "    if df2.where(col(column).isNull()).count() > 0:\n",
    "        Nulls = True\n",
    "        break\n",
    "\n",
    "if Nulls:\n",
    "    print(\"There are null values in the DataFrame.\")\n",
    "else:\n",
    "    print(\"There are NO null values in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d834f7b0-a7d2-4c72-be75-67b1f71169f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns \n",
    "df2 = df2.drop(\"number\",\"flag\",\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23c9b7e6-0c7c-436f-b1a5-e53926b78650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+--------------------+-------+----+---+--------+-----+\n",
      "|       _id|           user|               tweet|DayWeek|year|day|    hour|month|\n",
      "+----------+---------------+--------------------+-------+----+---+--------+-----+\n",
      "|1467810672|  scotthamilton|is upset that he ...| Monday|2009| 06|22:19:49|    4|\n",
      "|1467810917|       mattycus|@Kenichan I dived...| Monday|2009| 06|22:19:53|    4|\n",
      "|1467811184|        ElleCTF|my whole body fee...| Monday|2009| 06|22:19:57|    4|\n",
      "|1467811193|         Karoli|@nationwideclass ...| Monday|2009| 06|22:19:57|    4|\n",
      "|1467811372|       joy_wolf|@Kwesidei not the...| Monday|2009| 06|22:20:00|    4|\n",
      "|1467811592|        mybirch|         Need a hug | Monday|2009| 06|22:20:03|    4|\n",
      "|1467811594|           coZZ|@LOLTrish hey  lo...| Monday|2009| 06|22:20:03|    4|\n",
      "|1467811795|2Hood4Hollywood|@Tatiana_K nope t...| Monday|2009| 06|22:20:05|    4|\n",
      "|1467812025|        mimismo|@twittera que me ...| Monday|2009| 06|22:20:09|    4|\n",
      "|1467812416| erinx3leannexo|spring break in p...| Monday|2009| 06|22:20:16|    4|\n",
      "|1467812579|   pardonlauren|I just re-pierced...| Monday|2009| 06|22:20:17|    4|\n",
      "|1467812723|           TLeC|@caregiving I cou...| Monday|2009| 06|22:20:19|    4|\n",
      "|1467812771|robrobbierobert|@octolinz16 It it...| Monday|2009| 06|22:20:19|    4|\n",
      "|1467812784|    bayofwolves|@smarrison i woul...| Monday|2009| 06|22:20:20|    4|\n",
      "|1467812799|     HairByJess|@iamjazzyfizzle I...| Monday|2009| 06|22:20:20|    4|\n",
      "|1467812964| lovesongwriter|Hollis' death sce...| Monday|2009| 06|22:20:22|    4|\n",
      "|1467813137|       armotley|about to file taxes | Monday|2009| 06|22:20:25|    4|\n",
      "|1467813579|     starkissed|@LettyA ahh ive a...| Monday|2009| 06|22:20:31|    4|\n",
      "|1467813782|      gi_gi_bee|@FakerPattyPattz ...| Monday|2009| 06|22:20:34|    4|\n",
      "|1467813985|         quanvu|@alydesigns i was...| Monday|2009| 06|22:20:37|    4|\n",
      "+----------+---------------+--------------------+-------+----+---+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Final dataframe\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092cc7e4",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a3e24d",
   "metadata": {},
   "source": [
    "Text processing for analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5701141c-669e-463c-a916-98aa49ed003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "# tokenize tweets (breaking a sequence of text into smaller units, such as individual words or characters)\n",
    "tokenizer = Tokenizer(inputCol  = \"tweet\",\n",
    "                      outputCol = \"token\")\n",
    "\n",
    "df3 = tokenizer.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7af765e9-d334-4495-a5f2-1e358864c946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>DayWeek</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467810672</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2009</td>\n",
       "      <td>06</td>\n",
       "      <td>22:19:49</td>\n",
       "      <td>4</td>\n",
       "      <td>[is, upset, that, he, can't, update, his, face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467810917</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2009</td>\n",
       "      <td>06</td>\n",
       "      <td>22:19:53</td>\n",
       "      <td>4</td>\n",
       "      <td>[@kenichan, i, dived, many, times, for, the, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          _id           user  \\\n",
       "0  1467810672  scotthamilton   \n",
       "1  1467810917       mattycus   \n",
       "\n",
       "                                               tweet DayWeek  year day  \\\n",
       "0  is upset that he can't update his Facebook by ...  Monday  2009  06   \n",
       "1  @Kenichan I dived many times for the ball. Man...  Monday  2009  06   \n",
       "\n",
       "       hour month                                              token  \n",
       "0  22:19:49     4  [is, upset, that, he, can't, update, his, face...  \n",
       "1  22:19:53     4  [@kenichan, i, dived, many, times, for, the, b...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d2359f",
   "metadata": {},
   "source": [
    "Removes special characters, call outs and web addresses from tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50ef590c-7afe-41e0-ac70-d9259e04a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def removeRegex(tokens: list) -> list:\n",
    "    \n",
    "    expr    = '(@[A-Za-z0-a9_]+)|(#[A-Za-z0-9_]+)|'+\\\n",
    "              '(https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+)'\n",
    "        \n",
    "    regex   = re.compile(expr)\n",
    "\n",
    "    cleaned = [t for t in tokens if not(regex.search(t)) if len(t) > 0]\n",
    "\n",
    "    return list(filter(None, cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "140aa2db-fed9-47ea-b20b-88d444feb29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeWEBUDF = F.udf(removeRegex, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f73063",
   "metadata": {},
   "source": [
    "Removing non-english characters and returns lower case versions of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59c3cf82-d25f-42f2-9f5f-1257cbf8caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(tokens : list) -> list:\n",
    "    \n",
    "    subbed   = [re.sub(\"[^a-zA-Z]+\", \"\", s).lower() for s in tokens]\n",
    "    \n",
    "    filtered = filter(None, subbed)\n",
    "    \n",
    "    return list(filtered)\n",
    "\n",
    "\n",
    "normalizeUDF = F.udf(normalize, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea395c4e-a288-43bd-a325-877a72179dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.withColumn(\"tokens_re\", removeWEBUDF(df3[\"token\"]))\n",
    "\n",
    "df3 = df3.withColumn(\"tokens_clean\", normalizeUDF(df3[\"tokens_re\"]))\n",
    "\n",
    "# rename columns\n",
    "df4 = df3.drop(\"token\",\"tokens_re\")\n",
    "df4 = df4.withColumnRenamed(\"tokens_clean\", \"tokens\")\n",
    "\n",
    "# remove tweets where the tokens array is empty\n",
    "df5= df4.where(F.size(F.col(\"tokens\")) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f46c330-e8be-4803-be25-44f833091bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>DayWeek</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467810672</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2009</td>\n",
       "      <td>06</td>\n",
       "      <td>22:19:49</td>\n",
       "      <td>4</td>\n",
       "      <td>[is, upset, that, he, cant, update, his, faceb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467810917</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2009</td>\n",
       "      <td>06</td>\n",
       "      <td>22:19:53</td>\n",
       "      <td>4</td>\n",
       "      <td>[i, dived, many, times, for, the, ball, manage...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          _id           user  \\\n",
       "0  1467810672  scotthamilton   \n",
       "1  1467810917       mattycus   \n",
       "\n",
       "                                               tweet DayWeek  year day  \\\n",
       "0  is upset that he can't update his Facebook by ...  Monday  2009  06   \n",
       "1  @Kenichan I dived many times for the ball. Man...  Monday  2009  06   \n",
       "\n",
       "       hour month                                             tokens  \n",
       "0  22:19:49     4  [is, upset, that, he, cant, update, his, faceb...  \n",
       "1  22:19:53     4  [i, dived, many, times, for, the, ball, manage...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e067deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmongo= df5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
